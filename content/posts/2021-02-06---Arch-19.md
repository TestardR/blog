---
title: "Load Balancing"
date: "2021-02-06"
time: "☕️"
template: "post"
draft: false
slug: "Arch-19"
category: "Architecture"
description: "Let's take a look at Load Balancers with Design Gurus"
---

This article was done using my notes from:

<sub>Design Gurus, (2021), [Load Balancing](https://www.educative.io/courses/grokking-the-system-design-interview/3jEwl04BL7Q). educative.</sub></br>

## Definition

Load Balancer (LB) is a critical component of any distributed system. It helps to spread the traffic across a cluster of servers to improve responsiveness and availability of applications, websites or databases. LB also keeps track of the status of all the resources while distributing requests.

Typically a load balancer sits between the client and the server accepting incoming network and application traffic and distributing the traffic across multiple backend servers using various algorithms. By balancing application requests across multiple servers, a load balancer reduces individual server load and prevents any one application server from becoming a single point of failure, thus improving overall application availability and responsiveness.

![LB](/media/lb1.png)

To utilize full scalability and redundancy, we can try to balance the load at each layer of the system. We can add LBs at three places

![LB](/media/lb2.png)

## Benefits of Load Balancing

1. Users experience faster, uninterrupted service. Users won’t have to wait for a single struggling server to finish its previous tasks.
2. Service providers experience less downtime and higher throughput.
3. Load balancing makes it easier for system administrators to handle incoming requests while decreasing wait time for users.
4. Smart load balancers provide benefits like predictive analytics that determine traffic bottlenecks before they happen.
5. System administrators experience fewer failed or stressed components.

## Load Balancing Algorithms

Load balancers consider two factors before forwarding a request to a backend server. They will first ensure that the server they choose is actually responding appropriately to requests and then use a pre-configured algorithm to select one from the set of healthy servers.

Health Checks: If a server fails a health check, it is automatically removed from the pool, and traffic will not be forwarded to it until it responds to the health checks again.

1. Least Connection Method
2. Least Response Time Method
3. Least Bandwidth Method
4. Round Robin Method (LB sends each new request to the next server)
5. Weighted Round Robin Method
6. IP Hash

## Redundant Load Balancers

The load balancer can be a single point of failure; to overcome this, a second load balancer can be connected to the first to form a cluster. Each LB monitors the health of the other and, since both of them are equally capable of serving traffic and failure detection, in the event the main load balancer fails, the second load balancer takes over.
